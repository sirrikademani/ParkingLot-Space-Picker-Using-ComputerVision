{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6325ed7b",
   "metadata": {},
   "source": [
    "cv2 is an abbreviation for \"OpenCV\", which stands for Open Source Computer Vision Library. It is a popular open-source computer vision and machine learning software library used for real-time image and video processing. cv2 is a Python library that provides a Python interface to the OpenCV C++ library. It provides various functions and tools for image and video manipulation, feature detection, object recognition, and more. cv2 is widely used in academic research, industry, and hobbyist projects for a variety of applications such as robotics, surveillance, augmented reality, and medical imaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87bd77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import pickle\n",
    "import cvzone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video feed\n",
    "# Create a VideoCapture object to read from the input video file\n",
    "cap = cv2.VideoCapture('carPark.mp4')\n",
    "\n",
    "# Load the parking space positions from a saved file\n",
    "with open('CarParkPos','rb') as f:\n",
    "        posList= pickle.load(f)\n",
    "\n",
    "# Set the dimensions of each parking space\n",
    "width, height = 107, 48\n",
    "\n",
    "# Define a function to check whether a parking space is free or occupied\n",
    "def checkParkingSpace(imgPro):\n",
    "    \n",
    "     # Initialize a counter for the number of free parking spaces\n",
    "     spaceCounter = 0\n",
    "    \n",
    "     # Loop over each parking space position\n",
    "     for pos in posList:\n",
    "        # Get the x and y coordinates of the current parking space\n",
    "        x,y = pos\n",
    "            \n",
    "        # Crop the input image to the current parking space    \n",
    "        imgCrop = imgPro[y:y + height, x:x + width]\n",
    "        #cv2.imshow(str(x * y), imgCrop) #to show all diff images that we have, we need to have unique name for img, hence str(x*y)\n",
    "        # Count the number of non-zero pixels in the cropped image\n",
    "        count = cv2.countNonZero(imgCrop)\n",
    "        \n",
    "         #If the count is less than a threshold, the space is considered free\n",
    "        if count < 900:\n",
    "            color = (0,255,0) # green color for free parking space\n",
    "            thickness =  5\n",
    "            spaceCounter +=1\n",
    "            # Otherwise, the space is considered occupied\n",
    "        else:\n",
    "            color = (0,0,255) # red color for occupied parking space\n",
    "            thickness = 2\n",
    "            \n",
    "        # Draw a rectangle around the current parking space with the corresponding color\n",
    "        cv2.rectangle(img,pos,(pos[0] + width,pos[1] + height),color,2)\n",
    "        \n",
    "     # Add a text label showing the number of free parking spaces out of the total number of spaces   \n",
    "     cvzone.putTextRect(img,f'Free Spaces:{spaceCounter}/{len(posList)}', (100, 50), scale=3, thickness=5, offset=20, colorR=(0,200,0))           \n",
    "    \n",
    "    \n",
    "# Loop over each frame in the input video    \n",
    "while True:\n",
    "    \n",
    "    # If we have reached the end of the video, start over from the beginning\n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT): #CAP_PROP_POS_FRAMES-Gives us total frames we have in video\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,0)\n",
    "        \n",
    "    # Read the next frame from the video\n",
    "    success, img= cap.read()\n",
    "    \n",
    "    # Convert the image to grayscale and apply Gaussian blur to reduce noise\n",
    "    imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (3,3), 1)\n",
    "    \n",
    "    # Apply adaptive thresholding to obtain a binary image with the parking spaces highlighted\n",
    "    imgThreshold = cv2.adaptiveThreshold(imgBlur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        cv2.THRESH_BINARY_INV,25,16)\n",
    "    \n",
    "    # Apply median blur to further reduce noise\n",
    "    imgMedian = cv2.medianBlur(imgThreshold,5)\n",
    "    \n",
    "    # Apply dilation to increase the thickness of the white borders around the parking spaces\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    imgDilate = cv2.dilate(imgMedian,kernel, iterations=1)\n",
    "    \n",
    "    # Call the function to check each parking space and update the image accordingly\n",
    "    checkParkingSpace(imgDilate)\n",
    "\n",
    "    # Show the output image\n",
    "    cv2.imshow(\"Image\",img)\n",
    "    \n",
    "    #cv2.imshow(\"ImageBlur\",imgBlur)\n",
    "    #cv2.imshow(\"ImageThresh\",imgThreshold)\n",
    "    \n",
    "    # Apply median blur to further reduce noise\n",
    "    #cv2.imshow(\"ImageMedian\",imgMedian)\n",
    "    #cv2.imshow(\"ImageDilate\",imgDilate) #to increase the thickness of white borders\n",
    "    cv2.waitKey(10)  #10 to slow down the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f351ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
